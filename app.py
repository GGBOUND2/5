import streamlit as st
import pandas as pd
import numpy as np
import shap
import joblib
import json
from pathlib import Path
import matplotlib.pyplot as plt

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆå¿…é¡»å…ˆä¿®æ”¹è¿™é‡Œï¼ï¼‰=====================
# æ ¹æ®ä½ çš„æ¨¡å‹å®é™…ç±»åˆ«æ•°ä¿®æ”¹ï¼šäºŒåˆ†ç±»å¡«2ï¼Œä¸‰åˆ†ç±»å¡«3
ACTUAL_CLASSES = 3  
st.set_page_config(page_title="Doctors Visited Prediction", layout="wide")
plt.rcParams["font.sans-serif"] = ["SimHei"]  # è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
plt.rcParams["axes.unicode_minus"] = False

# ===================== è·¯å¾„ä¸èµ„æºåŠ è½½ =====================
PROJECT_ROOT = Path(__file__).parent
ART_DIR = PROJECT_ROOT / "output" / "artifacts"

# æ ¡éªŒæ ¸å¿ƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
required_files = [
    ART_DIR / "final_pipe_ds3.joblib",
    ART_DIR / "meta_ds3.json",
    ART_DIR / "bg_sample_ds3.csv"
]
for file_path in required_files:
    if not file_path.exists():
        st.error(f"æ ¸å¿ƒæ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š{file_path}")
        st.stop()

# åŠ è½½æ¨¡å‹ã€å…ƒæ•°æ®ã€èƒŒæ™¯æ ·æœ¬
try:
    model = joblib.load(ART_DIR / "final_pipe_ds3.joblib")
    with open(ART_DIR / "meta_ds3.json", "r", encoding="utf-8") as f:
        meta = json.load(f)
    bg = pd.read_csv(ART_DIR / "bg_sample_ds3.csv")
    # å¼ºåˆ¶ä¿ç•™æ¨¡å‹è®­ç»ƒçš„ç‰¹å¾åˆ—ï¼Œè¿‡æ»¤æ— å…³åˆ—
    bg = bg[meta["selected_features"]].copy()
    if bg.empty:
        st.error("èƒŒæ™¯æ ·æœ¬æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ bg_sample_ds3.csv æ–‡ä»¶")
        st.stop()
    # å»é‡+é‡ç½®ç´¢å¼•ï¼Œé¿å…èƒŒæ™¯æ•°æ®å¼‚å¸¸
    bg = bg.drop_duplicates().reset_index(drop=True)
except Exception as e:
    st.error(f"èµ„æºåŠ è½½å¤±è´¥ï¼š{str(e)}")
    st.stop()

# ===================== ä¾§è¾¹æ è¾“å…¥ç•Œé¢ =====================
st.title("åŒ»ç”Ÿè®¿é—®æ¬¡æ•°åˆ†ç±»é¢„æµ‹ & SHAP å¯è§£é‡Šæ€§åˆ†æ")
st.caption("ç¨³å®šç‰ˆ - å·²ä¿®å¤ç±»åˆ«æ•°å¯¹é½å’ŒSHAPå¯è§†åŒ–é—®é¢˜")

with st.sidebar:
    st.header("ç‰¹å¾è¾“å…¥")
    inputs = {}
    # æ•°å€¼ç‰¹å¾è¾“å…¥
    for col in meta["num_cols"]:
        col_range = meta["num_ranges"][col]
        val = st.number_input(
            label=col,
            min_value=float(col_range["min"]),
            max_value=float(col_range["max"]),
            value=float(col_range["mean"]),
            step=0.1
        )
        inputs[col] = val
    # åˆ†ç±»ç‰¹å¾è¾“å…¥
    for col in meta["cat_cols"]:
        options = meta["cat_values"].get(col, [])
        if options:
            val = st.selectbox(label=col, options=options, index=0)
        else:
            val = st.text_input(label=col, value="")
        inputs[col] = val
    # é¢„æµ‹æŒ‰é’®
    submit_btn = st.button("é¢„æµ‹å¹¶ç”ŸæˆSHAPåˆ†æ", type="primary")

# ===================== é¢„æµ‹ä¸SHAPåˆ†ææ ¸å¿ƒé€»è¾‘ =====================
if submit_btn:
    # 1. æ„é€ æ¨¡å‹è¾“å…¥æ•°æ®ï¼ˆä¸¥æ ¼åŒ¹é…ç‰¹å¾é¡ºåºï¼‰
    input_df = pd.DataFrame([inputs])[meta["selected_features"]]
    # æ•°æ®ç±»å‹å¯¹é½ï¼ˆé¿å…æ¨¡å‹é¢„æµ‹æ—¶ç±»å‹é”™è¯¯ï¼‰
    for col in meta["num_cols"]:
        if col in input_df.columns:
            input_df[col] = input_df[col].astype(float)

    # 2. æ¨¡å‹é¢„æµ‹ï¼ˆå¼ºåˆ¶æ ¼å¼æ ¡éªŒï¼Œé¿å…ç»´åº¦å¼‚å¸¸ï¼‰
    try:
        # è·å–é¢„æµ‹æ¦‚ç‡ï¼Œå¼ºåˆ¶è½¬ä¸ºäºŒç»´æ•°ç»„
        pred_proba = model.predict_proba(input_df)
        if pred_proba.ndim == 1:
            pred_proba = pred_proba.reshape(1, -1)
        
        # å¼ºåˆ¶å¯¹é½ç±»åˆ«æ•°ï¼ˆæˆªæ–­/è¡¥å…¨æ¦‚ç‡ï¼Œä¿è¯å’Œä¸º1ï¼‰
        if pred_proba.shape[1] != ACTUAL_CLASSES:
            if pred_proba.shape[1] > ACTUAL_CLASSES:
                pred_proba = pred_proba[:, :ACTUAL_CLASSES]  # æˆªæ–­å¤šä½™ç±»åˆ«
            else:
                # è¡¥å…¨ç¼ºå¤±ç±»åˆ«ï¼Œå‡åˆ†å‰©ä½™æ¦‚ç‡
                pad_proba = np.zeros((pred_proba.shape[0], ACTUAL_CLASSES - pred_proba.shape[1]))
                pad_proba += (1 - pred_proba.sum(axis=1, keepdims=True)) / pad_proba.shape[1]
                pred_proba = np.hstack([pred_proba, pad_proba])
            # é‡æ–°å½’ä¸€åŒ–ï¼Œç¡®ä¿æ¦‚ç‡å’Œä¸º1
            pred_proba = pred_proba / pred_proba.sum(axis=1, keepdims=True)
        
        # è®¡ç®—é¢„æµ‹ç±»åˆ«ï¼ˆå¼ºåˆ¶é™å®šåœ¨åˆæ³•èŒƒå›´ï¼‰
        pred_class = int(np.argmax(pred_proba[0]))
        pred_class = np.clip(pred_class, 0, ACTUAL_CLASSES - 1)
    except Exception as e:
        st.error(f"æ¨¡å‹é¢„æµ‹å¤±è´¥ï¼š{str(e)}")
        st.stop()

    # 3. å±•ç¤ºé¢„æµ‹ç»“æœ
    st.subheader("ğŸ“Š é¢„æµ‹ç»“æœ")
    result_cols = st.columns(ACTUAL_CLASSES)
    for idx in range(ACTUAL_CLASSES):
        with result_cols[idx]:
            prob_value = pred_proba[0][idx]
            delta = prob_value - (1/ACTUAL_CLASSES)
            st.metric(
                label=f"ç±»åˆ« {idx} æ¦‚ç‡",
                value=f"{prob_value:.3f}",
                delta=f"{delta:.3f}",
                delta_color="normal"
            )
    st.success(f"æœ€ç»ˆé¢„æµ‹ç±»åˆ«ï¼š**ç±»åˆ« {pred_class}**")

    # 4. SHAP å¯è§£é‡Šæ€§åˆ†æï¼ˆæ ¸å¿ƒä¿®å¤é€»è¾‘ï¼‰
    st.subheader("ğŸ” SHAP Waterfall ç‰¹å¾å½±å“åˆ†æ")
    
    # å®šä¹‰é€‚é…SHAPçš„é¢„æµ‹å‡½æ•°ï¼ˆå¼ºåˆ¶è¿”å›æŒ‡å®šç±»åˆ«æ•°çš„æ¦‚ç‡ï¼‰
    def shap_model_predict(arr):
        """é€‚é…SHAPçš„é¢„æµ‹å‡½æ•°ï¼Œç¡®ä¿è¾“å‡ºç±»åˆ«æ•°ä¸é…ç½®ä¸€è‡´"""
        df = pd.DataFrame(arr, columns=meta["selected_features"])
        # æ•°æ®ç±»å‹å¯¹é½
        for col in meta["num_cols"]:
            if col in df.columns:
                df[col] = df[col].astype(float)
        
        proba = model.predict_proba(df)
        if proba.ndim == 1:
            proba = proba.reshape(1, -1)
        
        # å¼ºåˆ¶å¯¹é½ç±»åˆ«æ•°
        if proba.shape[1] != ACTUAL_CLASSES:
            if proba.shape[1] > ACTUAL_CLASSES:
                proba = proba[:, :ACTUAL_CLASSES]
            else:
                pad = np.zeros((proba.shape[0], ACTUAL_CLASSES - proba.shape[1]))
                pad += (1 - proba.sum(axis=1, keepdims=True)) / pad.shape[1]
                proba = np.hstack([proba, pad])
        return proba / proba.sum(axis=1, keepdims=True)

    # åˆå§‹åŒ–SHAPè§£é‡Šå™¨ï¼ˆä¼˜åŒ–èƒŒæ™¯æ•°æ®å¤„ç†ï¼‰
    bg_arr = bg.values
    # ç¡®ä¿èƒŒæ™¯æ•°æ®æ˜¯äºŒç»´æ•°ç»„
    if bg_arr.ndim == 1:
        bg_arr = bg_arr.reshape(1, -1)
    # é™åˆ¶èƒŒæ™¯æ ·æœ¬æ•°ï¼ˆæœ€å¤š200ä¸ªï¼Œå¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®æ€§ï¼‰
    bg_sample = bg_arr[:min(200, len(bg_arr))]
    # ç¡®ä¿èƒŒæ™¯æ ·æœ¬æ•°ä¸å°‘äº1
    if len(bg_sample) == 0:
        st.error("èƒŒæ™¯æ ·æœ¬æ•°é‡ä¸è¶³ï¼Œæ— æ³•åˆå§‹åŒ–SHAPè§£é‡Šå™¨")
        st.stop()
    
    explainer = shap.KernelExplainer(shap_model_predict, bg_sample, seed=42)
    
    # è®¡ç®—SHAPå€¼ï¼ˆå¢åŠ å¼‚å¸¸æ•è·ï¼‰
    try:
        shap_vals = explainer.shap_values(input_df.values, nsamples=100)
    except Exception as e:
        st.error(f"SHAPå€¼è®¡ç®—å¤±è´¥ï¼š{str(e)}")
        st.stop()

    # è°ƒè¯•ä¿¡æ¯ï¼ˆä¾¿äºå®šä½é—®é¢˜ï¼‰
    st.info(f"""
    ğŸ“ è°ƒè¯•ä¿¡æ¯ï¼š
    - é…ç½®ç±»åˆ«æ•°ï¼š{ACTUAL_CLASSES}
    - SHAPå€¼ç±»å‹ï¼š{type(shap_vals)}
    - SHAPå€¼é•¿åº¦/å½¢çŠ¶ï¼š{len(shap_vals) if isinstance(shap_vals, list) else shap_vals.shape if hasattr(shap_vals, 'shape') else 'æœªçŸ¥'}
    - é¢„æµ‹ç±»åˆ«ï¼š{pred_class}
    - ç‰¹å¾æ•°ï¼š{len(meta["selected_features"])}
    - èƒŒæ™¯æ ·æœ¬æ•°ï¼š{len(bg_sample)}
    """)

    # å¼ºåˆ¶å¯¹é½SHAPå€¼ç»“æ„ï¼ˆæ ¸å¿ƒä¿®å¤ç´¢å¼•è¶Šç•Œï¼‰
    try:
        if isinstance(shap_vals, np.ndarray):
            # å¤„ç†æ•°ç»„ç±»å‹çš„SHAPå€¼
            if shap_vals.ndim == 3:
                # æ ‡å‡†å¤šåˆ†ç±»SHAPå€¼å½¢çŠ¶ï¼š(æ ·æœ¬æ•°, ç‰¹å¾æ•°, ç±»åˆ«æ•°)
                shap_vals = [shap_vals[:, :, i] for i in range(ACTUAL_CLASSES)]
            elif shap_vals.ndim == 2:
                # äºŒåˆ†ç±»/å•åˆ†ç±»æƒ…å†µï¼Œè½¬ä¸ºåˆ—è¡¨
                shap_vals = [shap_vals for _ in range(ACTUAL_CLASSES)]
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„SHAPå€¼ç»´åº¦ï¼š{shap_vals.ndim}")
        elif not isinstance(shap_vals, list):
            raise TypeError(f"SHAPå€¼ç±»å‹é”™è¯¯ï¼Œé¢„æœŸlist/ndarrayï¼Œå®é™…{type(shap_vals)}")

        # ç¡®ä¿SHAPå€¼åˆ—è¡¨é•¿åº¦åŒ¹é…ç±»åˆ«æ•°
        if len(shap_vals) != ACTUAL_CLASSES:
            if len(shap_vals) > ACTUAL_CLASSES:
                shap_vals = shap_vals[:ACTUAL_CLASSES]
            else:
                # è¡¥å…¨ç©ºSHAPå€¼
                empty_shape = (input_df.shape[0], len(meta["selected_features"]))
                empty_shap = np.zeros(empty_shape)
                shap_vals += [empty_shap] * (ACTUAL_CLASSES - len(shap_vals))

        # éªŒè¯å½“å‰ç±»åˆ«SHAPå€¼å½¢çŠ¶
        current_shap = shap_vals[pred_class]
        if current_shap.shape != (input_df.shape[0], len(meta["selected_features"])):
            raise ValueError(
                f"SHAPå€¼å½¢çŠ¶ä¸åŒ¹é…ï¼šé¢„æœŸ{(input_df.shape[0], len(meta['selected_features']))}ï¼Œ"
                f"å®é™…{current_shap.shape}"
            )

    except Exception as e:
        st.error(f"SHAPå€¼ç»“æ„ä¿®å¤å¤±è´¥ï¼š{str(e)}")
        st.stop()

    # ç»˜åˆ¶SHAP Waterfallå›¾
    try:
        # æå–å½“å‰é¢„æµ‹ç±»åˆ«çš„SHAPå€¼ï¼ˆå•æ ·æœ¬ï¼‰
        shap_row = current_shap[0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„SHAPå€¼
        feature_names = meta["selected_features"]
        
        # å¤„ç†åŸºå‡†å€¼ï¼ˆexpected_valueï¼‰
        base_value = explainer.expected_value
        if isinstance(base_value, (list, np.ndarray)):
            # ç¡®ä¿åŸºå‡†å€¼ç´¢å¼•ä¸è¶Šç•Œ
            base_value = base_value[pred_class] if pred_class < len(base_value) else np.mean(base_value)
        base_value = float(base_value)

        # ç”Ÿæˆç€‘å¸ƒå›¾
        fig, ax = plt.subplots(figsize=(12, 8))
        shap.plots._waterfall.waterfall_legacy(
            base_value=base_value,
            shap_values=shap_row,
            feature_names=feature_names,
            max_display=15,  # æœ€å¤šæ˜¾ç¤º15ä¸ªç‰¹å¾
            ax=ax,
            show=False
        )
        ax.set_title(f"ç±»åˆ« {pred_class} çš„SHAPç‰¹å¾å½±å“åˆ†æ", fontsize=14, pad=20)
        ax.tick_params(axis='x', labelsize=10)
        ax.tick_params(axis='y', labelsize=10)
        plt.tight_layout()
        st.pyplot(fig)

    except Exception as e:
        st.error(f"SHAPå›¾ç»˜åˆ¶å¤±è´¥ï¼š{str(e)}")
        # å…œåº•æ–¹æ¡ˆï¼šå±•ç¤ºSHAPå€¼è¡¨æ ¼
        st.subheader("ğŸ“‹ ç‰¹å¾SHAPå€¼æ˜ç»†ï¼ˆå…œåº•å±•ç¤ºï¼‰")
        shap_df = pd.DataFrame({
            "ç‰¹å¾åç§°": feature_names,
            "SHAPå€¼": shap_row
        }).sort_values(by="SHAPå€¼", ascending=False)
        st.dataframe(shap_df, use_container_width=True)

else:
    st.info("è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ å¡«å†™ç‰¹å¾å€¼ï¼Œç‚¹å‡»ã€Œé¢„æµ‹å¹¶ç”ŸæˆSHAPåˆ†æã€æŒ‰é’®å¼€å§‹åˆ†æ")